{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  label hashtags  \\\n0   post claim compulsory vaccination violates pri...      0       []   \n1   photo claim person doctor died attending covid...      0       []   \n2   post video claim protest confiscation town ama...      0       []   \n3   death respiratory failure pneumonia registered...      0       []   \n4   dean college biologist adieu state lot cpr fal...      0       []   \n5   household covid patient porto allegra campos g...      0       []   \n6   chain list recommendation prevent treat corona...      0       []   \n7   60000 argentinian company closed due covid com...      0       []   \n8   social medium post criticize photo smiling pre...      0       []   \n9         cdc released update coronavirus transmitted      0       []   \n10  oral hygiene destroys coronavirus prevents spread      0       []   \n11  video show pakistani minister health slapping ...      0       []   \n12  brazilian depute pandemic started decrease sta...      0       []   \n13              warns consuming cabbage prevent covid      0       []   \n14  picture show hydrocortisone sold public train ...      0       []   \n15               evidence chlorine dioxide cure covid      0       []   \n16  video show pakistani minister health slapping ...      0       []   \n17  picture show hydrocortisone sold public train ...      0       []   \n18             coronavirus settle air grounded unicef      0       []   \n\n          emojis  polarity  subjectivity sentiment  \n0   [trade_mark]  0.033333      0.500000  positive  \n1             []  0.500000      0.500000  positive  \n2             []  0.000000      0.000000   neutral  \n3             [] -0.316667      0.300000  negative  \n4   [trade_mark] -0.400000      0.600000  negative  \n5             []  0.000000      0.000000   neutral  \n6             []  0.000000      0.000000   neutral  \n7             [] -0.112500      0.237500  negative  \n8             []  0.033333      0.066667  positive  \n9             []  0.000000      0.000000   neutral  \n10            []  0.700000      0.600000  positive  \n11            []  0.000000      0.000000   neutral  \n12            []  0.000000      0.000000   neutral  \n13            []  0.000000      0.000000   neutral  \n14            []  0.000000      0.066667   neutral  \n15            []  0.000000      0.000000   neutral  \n16            []  0.000000      0.000000   neutral  \n17            []  0.000000      0.066667   neutral  \n18            []  0.000000      0.000000   neutral  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>hashtags</th>\n      <th>emojis</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>post claim compulsory vaccination violates pri...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[trade_mark]</td>\n      <td>0.033333</td>\n      <td>0.500000</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>photo claim person doctor died attending covid...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>post video claim protest confiscation town ama...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>death respiratory failure pneumonia registered...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>-0.316667</td>\n      <td>0.300000</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dean college biologist adieu state lot cpr fal...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[trade_mark]</td>\n      <td>-0.400000</td>\n      <td>0.600000</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>household covid patient porto allegra campos g...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>chain list recommendation prevent treat corona...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>60000 argentinian company closed due covid com...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>-0.112500</td>\n      <td>0.237500</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>social medium post criticize photo smiling pre...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.033333</td>\n      <td>0.066667</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cdc released update coronavirus transmitted</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>oral hygiene destroys coronavirus prevents spread</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.700000</td>\n      <td>0.600000</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>video show pakistani minister health slapping ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>brazilian depute pandemic started decrease sta...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>warns consuming cabbage prevent covid</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>picture show hydrocortisone sold public train ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.066667</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>evidence chlorine dioxide cure covid</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>video show pakistani minister health slapping ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>picture show hydrocortisone sold public train ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.066667</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>coronavirus settle air grounded unicef</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"../data/preprocessed/covid_test\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"label\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.3, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/5.03k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c479a007a745471eb48050bff8046f57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/2.02k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a4c5a4129764344add6505e91ff9437"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/7.25k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee76cec922a84b71a55f6d91c34bc828"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset rotten_tomatoes/default to C:/Users/Yaroslav/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07c68a59dbc240c5813ac43da9397a07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da3d07bffb6c49ac89951a031e7e18c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d0dad5e814a4194a59ca5b39dee40af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a26740636e44414a95d990d82f59707a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset rotten_tomatoes downloaded and prepared to C:/Users/Yaroslav/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e84e5bb66c2047eca9b9653514810eeb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "958a89c155184fdd9216c54567f16b36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yaroslav\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Yaroslav\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ea49141064e467f97012ebf7161a42a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb1068e1790f4717a6df6f75981dd2ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "574e5845e85d4961b657acbd8473b34d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading tf_model.h5:   0%|          | 0.00/363M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49d5d479c2634f7e939cfa82cb0f58de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03469567daeb4adabca9ebd3043a3565"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c31e2a06aae4c65af2a8417da5f04c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "426abc72d3a442d78cb6651d56a49f66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = model.prepare_tf_dataset(\n",
    "    dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yaroslav\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "533/533 [==============================] - 995s 2s/step - loss: 0.4136\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1ecefac30d0>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(3e-5))\n",
    "model.fit(tf_dataset)  # doctest: +SKIP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 8530\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 1066\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 1066\n    })\n})"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"text\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cześć?\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "text = \"Hi?\"\n",
    "\n",
    "def translate(text):\n",
    "    translator = Translator()\n",
    "\n",
    "    try:\n",
    "        translated = translator.translate(text, dest=\"pl_PL\")\n",
    "        return translated.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(translate(text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'ntpath' from 'c:\\\\users\\\\yaroslav\\\\appdata\\\\local\\\\programs\\\\python\\\\python38\\\\lib\\\\ntpath.py'>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spylls.hunspell import Dictionary\n",
    "import os\n",
    "# Dictionary.from_files(\"pl_PL\")\n",
    "os.path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
