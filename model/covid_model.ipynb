{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  label hashtags  \\\n0   post claim compulsory vaccination violates pri...      0       []   \n1   photo claim person doctor died attending covid...      0       []   \n2   post video claim protest confiscation town ama...      0       []   \n3   death respiratory failure pneumonia registered...      0       []   \n4   dean college biologist adieu state lot cpr fal...      0       []   \n5   household covid patient porto allegra campos g...      0       []   \n6   chain list recommendation prevent treat corona...      0       []   \n7   60000 argentinian company closed due covid com...      0       []   \n8   social medium post criticize photo smiling pre...      0       []   \n9         cdc released update coronavirus transmitted      0       []   \n10  oral hygiene destroys coronavirus prevents spread      0       []   \n11  video show pakistani minister health slapping ...      0       []   \n12  brazilian depute pandemic started decrease sta...      0       []   \n13              warns consuming cabbage prevent covid      0       []   \n14  picture show hydrocortisone sold public train ...      0       []   \n15               evidence chlorine dioxide cure covid      0       []   \n16  video show pakistani minister health slapping ...      0       []   \n17  picture show hydrocortisone sold public train ...      0       []   \n18             coronavirus settle air grounded unicef      0       []   \n\n          emojis  polarity  subjectivity sentiment  \n0   [trade_mark]  0.033333      0.500000  positive  \n1             []  0.500000      0.500000  positive  \n2             []  0.000000      0.000000   neutral  \n3             [] -0.316667      0.300000  negative  \n4   [trade_mark] -0.400000      0.600000  negative  \n5             []  0.000000      0.000000   neutral  \n6             []  0.000000      0.000000   neutral  \n7             [] -0.112500      0.237500  negative  \n8             []  0.033333      0.066667  positive  \n9             []  0.000000      0.000000   neutral  \n10            []  0.700000      0.600000  positive  \n11            []  0.000000      0.000000   neutral  \n12            []  0.000000      0.000000   neutral  \n13            []  0.000000      0.000000   neutral  \n14            []  0.000000      0.066667   neutral  \n15            []  0.000000      0.000000   neutral  \n16            []  0.000000      0.000000   neutral  \n17            []  0.000000      0.066667   neutral  \n18            []  0.000000      0.000000   neutral  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>hashtags</th>\n      <th>emojis</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>post claim compulsory vaccination violates pri...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[trade_mark]</td>\n      <td>0.033333</td>\n      <td>0.500000</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>photo claim person doctor died attending covid...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>post video claim protest confiscation town ama...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>death respiratory failure pneumonia registered...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>-0.316667</td>\n      <td>0.300000</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dean college biologist adieu state lot cpr fal...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[trade_mark]</td>\n      <td>-0.400000</td>\n      <td>0.600000</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>household covid patient porto allegra campos g...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>chain list recommendation prevent treat corona...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>60000 argentinian company closed due covid com...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>-0.112500</td>\n      <td>0.237500</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>social medium post criticize photo smiling pre...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.033333</td>\n      <td>0.066667</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cdc released update coronavirus transmitted</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>oral hygiene destroys coronavirus prevents spread</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.700000</td>\n      <td>0.600000</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>video show pakistani minister health slapping ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>brazilian depute pandemic started decrease sta...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>warns consuming cabbage prevent covid</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>picture show hydrocortisone sold public train ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.066667</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>evidence chlorine dioxide cure covid</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>video show pakistani minister health slapping ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>picture show hydrocortisone sold public train ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.066667</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>coronavirus settle air grounded unicef</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "data_json = pd.read_json(\"../data/preprocessed/covid_test\")\n",
    "data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[['trade_mark'],\n [],\n [],\n [],\n ['trade_mark'],\n [],\n [],\n [],\n [],\n [],\n [],\n [],\n [],\n [],\n [],\n [],\n [],\n [],\n []]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "schema = pa.schema([\n",
    "    (\"text\", pa.string()),\n",
    "    (\"label\", pa.int64()),\n",
    "    (\"hashtags\", pa.list_(pa.string())),\n",
    "    (\"emojis\", pa.list_(pa.string())),\n",
    "    (\"polarity\", pa.float64()),\n",
    "    (\"subjectivity\", pa.float64()),\n",
    "    (\"sentiment\", pa.string()),\n",
    "])\n",
    "\n",
    "arrow_table = pa.Table.from_batches([], schema=schema)\n",
    "\n",
    "dataset = Dataset(arrow_table=arrow_table)\n",
    "dataset = dataset.from_pandas(data_json)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_19', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/19 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7faee3573ac41089d64de640f687b52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_dataset)\n",
    "tf_dataset = model.prepare_tf_dataset(\n",
    "    dataset, batch_size=16, shuffle=True, tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yaroslav\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.7033\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f3bfa3c640>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(3e-5))\n",
    "model.fit(tf_dataset)  # doctest: +SKIP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
